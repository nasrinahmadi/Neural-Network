Let’s first load the required HR dataset using pandas’ read CSV function. You can download data from https://www.kaggle.com/datasets/liujiaqi/hr-comma-sepcsv 
import numpy as np
import pandas as pd

#load data
data pd.read_csv('HR_comma_sep.csv')
data.head()

Lots of machine learning algorithms require numerical input data, so you need to represent categorical columns in a numerical column. In order to encode this data, you could map each value to a number. e.g. Salary column’s value can be represented as low:0, medium:1, and high:2. This process is known as label encoding. In sklearn, we can do this using LabelEncoder.
#import LabelEncoder
from sklearn import preprocessing

#creating LabelEncoder
le = preprocessing.LabelEncoder()
#converting string labels into numbers
data['salary'] = le.fit_transform(data['salary'])
data['Departments']= le.fit_transform(data['Departments'])
Here, we imported the preprocessing module and created the Label Encoder object. Using this LabelEncoder object you fit and transform the “salary” and “Departments “ column into the numeric column.


In order to assess the model performance, we need to divide the dataset into a training set and a test set. Let’s split dataset by using function train_test_split(). you need to pass basically 3 parameters features, target, and test_set size. 
#spliting data into feature and
X = data['satisfaction_level', 'last_evaluation', 'number_project', 'average_montly_hours', 'time_spend_company', 'work_accident', 'promotion_last_5years', 'Departments', 'salary']
y = data['left']
#import train_test split function
from sklearn.model_selection import train_test_split

#split dataset into training set and test set
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3, random_state = 42, )     # 70% training and 30% test

Let’s build an employee churn prediction model. Here, our objective is to predict churn using MLPClassifier.

First, import the MLPClassifier module and create MLP Classifier object using MLPClassifier() function. Then, fit your model on the train set using fit() and perform prediction on the test set using predict().
#import MLPClassifier
from sklearn.neural_network import MLPClassifier

#creat model object
clf = MLPClassifier(hidden_layer_sizes = (6,5),
                    random_state = 5,
                    verbose = True,
                    learning_rate_init = 0.01)

#fit data onto the model
clf.fit(X_train,y_train)
Parameters:

hidden_layer_sizes: it is a tuple where each element represents one layer and its value represents the number of neurons on each hidden layer.
learning_rate_init: It used to controls the step-size in updating the weights. 
activation: Activation function for the hidden layer. Examples, identity, logistic, tanh, and relu. by default, relu is used as an activation function.
random_state: It defines the random number for weights and bias initialization. 
verbose: It used to print progress messages to standard output.

In this section, we will make predictions on the test dataset and assess model accuracy based on available actual labels of the test dataset. 
#make prediction on test dataset
ypred = clf.predict(X_test)

#import accuracy score
from sklearn.metrics import accuracy_score

#calculate accuracy
accuracy_score(y_test, ypred)

Well, you got a classification rate of 93.8%, considered as good accuracy.
